"""
Script de teste simples para verificar se o scraper estÃ¡ funcionando
"""

from zap_scraper import ZapScraper
import time

def teste_simples():
    """Teste simples com URL bÃ¡sica"""
    
    # URL simples de teste
    url_teste = "https://www.zapimoveis.com.br/venda/apartamentos/sp+sao-paulo/?pagina=1"
    
    print("ğŸ” Teste simples do scraper...")
    print(f"URL: {url_teste}")
    print("=" * 60)
    
    # Criar instÃ¢ncia do scraper
    scraper = ZapScraper()
    
    try:
        print("ğŸš€ Iniciando teste...")
        
        # Configurar driver
        if not scraper.configure_driver():
            print("âŒ Erro ao configurar driver")
            return
        
        print("âœ… Driver configurado")
        
        # Acessar pÃ¡gina
        scraper.driver.get(url_teste)
        time.sleep(5)
        
        print("âœ… PÃ¡gina acessada")
        
        # Aguardar elementos
        from selenium.webdriver.common.by import By
        from selenium.webdriver.support.ui import WebDriverWait
        from selenium.webdriver.support import expected_conditions as EC
        
        try:
            WebDriverWait(scraper.driver, 15).until(
                EC.presence_of_element_located((By.CLASS_NAME, "flex.flex-col.grow.min-w-0"))
            )
            print("âœ… Elementos detectados")
        except:
            print("âš ï¸ Timeout aguardando elementos")
        
        # Fazer scroll
        print("\nğŸ“œ Fazendo scroll...")
        num_elementos = scraper.scroll_page()
        print(f"âœ… Scroll concluÃ­do. Elementos: {num_elementos}")
        
        # Encontrar elementos
        elementos = scraper.driver.find_elements(By.CLASS_NAME, "flex.flex-col.grow.min-w-0")
        print(f"âœ… Elementos encontrados para processar: {len(elementos)}")
        
        # Processar alguns elementos
        if elementos:
            print(f"\nğŸ“Š Processando primeiros {min(3, len(elementos))} elementos...")
            
            for i, elemento in enumerate(elementos[:3]):
                try:
                    from bs4 import BeautifulSoup
                    html_content = elemento.get_attribute('outerHTML')
                    soup = BeautifulSoup(html_content, 'html.parser')
                    dados = scraper.extrair_dados_anuncio(soup)
                    
                    if dados:
                        print(f"âœ… Elemento {i+1}: {dados.get('Localidade', 'N/A')} - R$ {dados.get('Preco', 'N/A')}")
                        scraper.data_list.append(dados)
                    else:
                        print(f"âš ï¸ Elemento {i+1}: NÃ£o retornou dados")
                except Exception as e:
                    print(f"âŒ Elemento {i+1}: Erro - {e}")
        
        print(f"\nğŸ“‹ Total de dados coletados: {len(scraper.data_list)}")
        
        if scraper.data_list:
            # Salvar dados
            import pandas as pd
            df = pd.DataFrame(scraper.data_list)
            df.to_csv("teste_simples.csv", index=False)
            print("ğŸ’¾ Dados salvos em 'teste_simples.csv'")
            
            # Mostrar resumo
            print("\nğŸ“Š Resumo dos dados:")
            print(df.to_string())
        
    except Exception as e:
        print(f"âŒ Erro durante o teste: {e}")
        
    finally:
        try:
            if scraper.driver:
                scraper.driver.quit()
        except:
            pass

if __name__ == "__main__":
    teste_simples()
